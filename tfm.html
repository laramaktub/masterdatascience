<!doctype html>
<!--[if IE 7 ]>    <html lang="en-gb" class="isie ie7 oldie no-js"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en-gb" class="isie ie8 oldie no-js"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en-gb" class="isie ie9 no-js"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en-gb" class="no-js"> <!--<![endif]-->

<head>
    <title>Master en Data Science</title>

    <meta charset="utf-8">
    <meta name="keywords" content="Master,Data,Science,CSIC,UIMP,UC" />
    <meta name="description" content="Master en Data Science impartido por el CSIC, UIMP y UC" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

    <!-- Favicon --> 
    <link rel="shortcut icon" href="images/favicon.ico">

    <!-- this styles only adds some repairs on idevices  -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Google fonts - witch you want to use - (rest you can just remove) -->
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Raleway:100,200,300,400,500,600,700,800,900' rel='stylesheet' type='text/css'>

    <!--[if lt IE 9]>
        <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- ######### CSS STYLES ######### -->

    <link rel="stylesheet" href="css/reset.css" type="text/css" />
    <link rel="stylesheet" href="css/style.css" type="text/css" />

    <link rel="stylesheet" href="css/font-awesome/css/font-awesome.min.css">

    <!-- responsive devices styles -->
    <link rel="stylesheet" media="screen" href="css/responsive-leyouts.css" type="text/css" />

<!-- just remove the below comments witch color skin you want to use -->
    <!--<link rel="stylesheet" href="css/colors/blue.css" />-->
    <!--<link rel="stylesheet" href="css/colors/green.css" />-->
    <!--<link rel="stylesheet" href="css/colors/cyan.css" />-->
    <!--<link rel="stylesheet" href="css/colors/orange.css" />-->
    <!--<link rel="stylesheet" href="css/colors/lightblue.css" />-->
    <!--<link rel="stylesheet" href="css/colors/pink.css" />-->
    <!--<link rel="stylesheet" href="css/colors/purple.css" />-->
    <!--<link rel="stylesheet" href="css/colors/bridge.css" />-->
    <!--<link rel="stylesheet" href="css/colors/slate.css" />-->
    <!--<link rel="stylesheet" href="css/colors/yellow.css" />-->
    <!--<link rel="stylesheet" href="css/colors/darkred.css" />-->

<!-- just remove the below comments witch bg patterns you want to use --> 
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-default.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-one.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-two.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-three.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-four.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-five.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-six.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-seven.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-eight.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-nine.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-ten.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-eleven.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-twelve.css" />-->
    <!--<link rel="stylesheet" href="css/bg-patterns/pattern-thirteen.css" />-->

    <!-- mega menu -->
    <link href="js/mainmenu/sticky.css" rel="stylesheet">
    <link href="js/mainmenu/bootstrap.css" rel="stylesheet">
    <link href="js/mainmenu/fhmm.css" rel="stylesheet">

    <!-- REVOLUTION SLIDER -->
    <link rel="stylesheet" type="text/css" href="js/revolutionslider/rs-plugin/css/settings.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="js/revolutionslider/css/slider_main.css" media="screen" />

    <!-- cubeportfolio -->
    <link rel="stylesheet" type="text/css" href="js/cubeportfolio/cubeportfolio.min.css">

    <!-- tabs -->
    <link rel="stylesheet" type="text/css" href="js/tabs/assets/css/responsive-tabs.css">
    <link rel="stylesheet" type="text/css" href="js/tabs/assets/css/responsive-tabs2.css">
    <link rel="stylesheet" type="text/css" href="js/tabs/assets/css/responsive-tabs3.css">

    <!-- carousel -->
    <link rel="stylesheet" href="js/carousel/flexslider.css" type="text/css" media="screen" />
    <link rel="stylesheet" type="text/css" href="js/carousel/skin.css" />

    <!-- progressbar -->
    <link rel="stylesheet" href="js/progressbar/ui.progress-bar.css">

    <!-- accordion -->
    <link rel="stylesheet" href="js/accordion/accordion.css" type="text/css" media="all">

    <!-- Lightbox -->
    <link rel="stylesheet" type="text/css" href="js/lightbox/jquery.fancybox.css" media="screen" />
</head>



<body>

<div class="site_wrapper">

<header id="header">
    <!-- Top header bar -->
    <div id="topHeader">

    <div class="wrapper">
        <div class="top_nav">
        <div class="container">
        <div class="left">
            <ul>
                <li><a href="contacto.html"><i class="fa fa-envelope"></i> contacto</a></li>
            </ul>
        </div>
        <div class="right">
            <ul>
                <li>
                    <a class="fancybox fancybox.ajax" href="frame_idioma.html">
                        <img src="images/banderas/3/esp.gif" height="9"/>
                    </a>
                </li>
                <li>
                    <a class="fancybox fancybox.ajax" href="frame_idioma.html">
                        <img src="images/banderas/3/uk.gif" height="9"/>
                    </a>
                </li>
            </ul>
        </div>
        </div>
        </div>
    </div>


    <div id="trueHeader">
    <div class="wrapper">
    <div class="container">
        <!-- Logo -->
        <div class="logo"><a href="index.html" id="logo"></a></div>
        <!-- Menu -->
        <div class="menu_main">
          <nav class="navbar navbar-default fhmm" role="navigation">
             <div class="navbar-header">
                <button type="button" data-toggle="collapse" data-target="#defaultmenu" class="navbar-toggle">Menu <i class="fa fa-bars tbars"></i></button>
             </div>
             <div id="defaultmenu" class="navbar-collapse collapse">
                <ul class="nav navbar-nav">
                    <li class="dropdown">
                        <a href="index.html">Inicio</a>
                        <ul class="dropdown-menu" role="menu">
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="preinscripcion.html">Preinscripción</a>
                        <ul class="dropdown-menu" role="menu">
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="matricula.html">Matrícula</a>
                        <ul class="dropdown-menu" role="menu">
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="m01.html">Materias</a>
                        <ul class="dropdown-menu" role="menu">
                        </ul>
                    </li>
                    <li class="dropdown active">
                        <a href="tfm.html">Ofertas TFM</a>
                        <ul class="dropdown-menu" role="menu">
                    </ul>
                    </li>
                    <li class="dropdown">
                        <a href="faq.html">FAQ</a>
                        <ul class="dropdown-menu" role="menu">
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="contacto.html">Contacto</a>
                        <ul class="dropdown-menu" role="menu">
                        </ul>
                    </li>
                </ul>
            </div>
          </nav>
        </div>
        </div>
    </div>
    </div>
</header>



<div class="clearfix"></div>



<div class="page_title2">
<div class="container">
    <div class="title"><h1>Ofertas TFM</h1></div>
    <div class="pagenation">&nbsp;<a href="index.html">Inicio</a> <i>/</i> <a href="#">Páginas</a> <i>/</i> Ofertas TFM</div>
</div>
</div>



<div class="clearfix"></div>

<div class="container">


 <div class="content_fullwidth">
        <p><h2><center>Ofertas TFM</center></h2></p>
        <p align="center">En este apartado podr&aacute; encontrar los Trabajos Fin de Master ofertados.<br/><br/>
        Si desea ofertar un nuevo TFM (empresa o profesor) puede rellenar el siguiente formulario: 
        <a href="https://tinyurl.com/yb45hpch"> Propuesta de TFM</a> 
        <br/><br/>
    </div>

	<div class="content_fullwidth">
    <div class="accrodation">
         <p><b>Ofertas TFM 2020-2021</b></p>
         <br/>
    	
    	<!-- section 1 -->
        <span class="acc-trigger active"><a href="#">1.- Automatic Data Curation tool</a></span>
        <div class="acc-container">
        <div class="content">
Asegurar no sólo la accesibilidad de los datos, sino también su calidad para que puedan ser reutilizados para obtener información, es un reto al que se enfrentan tanto empresas como disciplinas científicas. Este trabajo desarrollará una herramienta para automatizar procesos para mejorar la calidad de los datos procedentes de fuentes en abierto, aplicando métodos de curación a diferentes conjuntos de datos.
<br>
<br>
Responsable: Fernando Aguilar
<br>Contacto: <b>aguilarf@ifca.unican.es</b>
        </div>
        </div>
    	<!-- section 2 -->
        <span class="acc-trigger active"><a href="#">2.- Cinco estrellas para repositorios de datos en abierto </a></span>
        <div class="acc-container">
        <div class="content">
Tim Berners-Lee, el inventor de la Web e iniciador de los Datos Enlazados (Linked Data), sugirió un esquema de desarrollo de 5 estrellas para Datos Abiertos. Dentro de los distintos tipos de repositorios de datos en abierto disponibles (gubernamentales, científicos, sociales) el nivel de adopción de este esquema es bastante desigual. El trabajo a desarrollar analizará varios repositorios con el fin de ver qué medidas se podrían tomar para conseguir que los datos publicados puedan ser fácilmente reutilizables.
<br>
<br>
Responsable: Fernando Aguilar
<br>Contacto: <b>aguilarf@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 3 -->
        <span class="acc-trigger active"><a href="#">3.- Estimación del número de personas en imágenes mediante muestreo geométrico</a></span>
        <div class="acc-container">
        <div class="content">
Analizaremos la precisión del método CountEm ( countem.unican.es ) de forma similar a lo realizado en el artículo <a>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141868</a> pero con los datos UCF-QNRF - A Large Crowd Counting Data Set <a>http://crcv.ucf.edu/data/ucf-qnrf/</a>      
<br>
<br>
Responsable: Marcos Cruz
<br>Contacto: <b>marcos.cruz@unican.es</b>
        </div>
        </div>

    	<!-- section 4 -->
        <span class="acc-trigger active"><a href="#">4.- Entrenamiento de redes neuronales con muestras sesgadas</a></span>
        <div class="acc-container">
        <div class="content">
En este trabajo se comprobará mediante técnicas de data augmentation si se puede mejorar la respuesta de ANN convencionales en casos en los que las muestras de entrenamiento presenten sesgos en alguna de sus variables.
<br>
<br>
Responsable: Francisco Matorras
<br>Contacto: <b>francisco.matorras@unican.es</b>

        </div>
        </div>


    	<!-- section 5 -->
        <span class="acc-trigger active"><a href="#">5.- Desarrollo de APIs para repositorios científicos</a></span>
        <div class="acc-container">
        <div class="content">
El creciente número de datasets científicos aumenta enormemente las posibilidades de reutilización de datos de calidad. Sin embargo, en ocasiones, los repositorios en los que se alojan no son lo suficientemente potentes para hacer un uso masivo de esos datos disponibles. Este trabajo propondrá y desarrollará APIs o plugins para aumentar las funcionalidades de repositorios científicos cpmo digital CSIC.
<br>
<br>
Responsable: Isabel Bernal
<br>Contacto: <b>isabel.bernal@bib.csic.es</b>

        </div>
        </div>




    	<!-- section 6 -->
        <span class="acc-trigger active"><a href="#">6.- Massive Parallel Machine Learning: evaluation of parallel processing implementations</a></span>
        <div class="acc-container">
        <div class="content">
The term massively parallel processing refers to the coordinated usage of a large number of processors or separate computers to carry out a given task. Generally speaking two kinds of parallelism exist: data and model parallelism. In this work we propose that the student performs a survey and state of the art evaluation of the existing parallel implementations for machine learning frameworks and libraries.
<br>
<br>
Responsable: Álvaro López
<br>Contacto: <b>aloga@ifca.unican.es</b>

        </div>
        </div>

    	<!-- section 7 -->
        <span class="acc-trigger active"><a href="#">7.- Massive Parallel Deep Learning: evaluation of parallel processing implementations</a></span>
        <div class="acc-container">
        <div class="content">
The term massively parallel processing refers to the coordinated usage of a large number of processors or separate computers to carry out a given task. Generally speaking two kinds of parallelism exist: data and model parallelism. In this work we propose that the student performs a survey and state of the art evaluation of the existing parallel implementations for deep learning frameworks and libraries.
<br>
<br>
Responsable: Álvaro López
<br>Contacto: <b>aloga@ifca.unican.es</b>


        </div>
        </div>



    	<!-- section 8 -->
        <span class="acc-trigger active"><a href="#">8.- Selección de predictores para la generación de modelos predictivos de Ciclones Tropicales. </a></span>
        <div class="acc-container">
        <div class="content">
A pesar del gran impacto de los eventos extremos asociados a la ocurrencia de ciclones, tanto en el trópico como en latitudes medias (p.e. Europa), la génesis y el desarrollo de este tipo de eventos depende de factores muy diversos (región, estación del año, etc.) por lo que, de cara a proponer un modelo de predicción, es necesario el desarrollo de algoritmos de selección de variables que permitan la detección de aquellos predictores relevantes para el evento de estudio. En el presente trabajo se propone implementar y validar usando la base de datos de referencia para la WMO, IBTrACS-WMO, un algoritmo de selección de variables basado en grafos que identifique, a partir de un número elevado de posibles predictores, aquellos que den lugar a una mejor modelización de la ocurrencia de estos eventos.
<br>
<br>
Responsable: Sixto Herrera
<br>Contacto: <b>herreras@unican.es</b>
        </div>
        </div>


    	<!-- section 9 -->
        <span class="acc-trigger active"><a href="#">9.- Clustering of Russian Troll Tweets</a></span>
        <div class="acc-container">
        <div class="content">
A data set contaning almost 3 million tweets from accounts associated with the Internet Research Agency has been made available thanks to the work of two professors at Clemson University: Darren Linvill and Patrick Warren. Using advanced social media tracking software, they pulled the tweets from thousands of accounts that Twitter has acknowledged as being associated with the IRA. The student will use unsuprevised learning to explore the dataset and try to find unknown patterns in the tweets.
<br>
<br>
Responsable: David Rodríguez
<br>Contacto: <b>drodrig@ifca.unican.es</b>
        </div>
        </div>

    	<!-- section 10 -->
        <span class="acc-trigger active"><a href="#">10.- Supervised learning for classifying Russian Troll Tweets</a></span>
        <div class="acc-container">
        <div class="content">
A data set contaning almost 3 million tweets from accounts associated with the Internet Research Agency has been made available thanks to the work of two professors at Clemson University: Darren Linvill and Patrick Warren. Using advanced social media tracking software, they pulled the tweets from thousands of accounts that Twitter has acknowledged as being associated with the IRA. The student will use supervised learning to build a classifier that groups the tweets according to the Troll category attributed by the Clemson University researchers (Right Troll, Left Troll, Newsfeed, Hashtag gamer and fearmonger).
<br>
<br>
Responsable:David Rodríguez
<br>Contacto: <b>drodrig@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 11 -->
        <span class="acc-trigger active"><a href="#">11.- Modelos de extremos no estacionarios aplicados al oleaje </a></span>
        <div class="acc-container">
        <div class="content">
En los últimos años, se ha producido un importante avance en la definición de modelos de extremos no estacionarios permitiendo caracterizar la distribución estadística de los extremos (parámetros de localización, escala y forma) condicionada a diversas escalas temporales (estacionalidad, variabilidad interanual, tendencia de largo plazo). El objetivo de este trabajo es desarrollar una librería de funciones de Python para el modelado de series de extremos no estacionarios a partir de modelos lineales multivariados heterocedásticos o a partir de redes neuronales y su aplicación a series temporales de datos de oleaje del reanálisis CSIRO y de satélite.

<br>
<br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>

        </div>
        </div>
 



    	<!-- section 12 -->
        <span class="acc-trigger active"><a href="#">12.- Optimización de la simulación numérica del Sistema de Alerta de Tsunamis (IH-Tsusy) </a></span>
        <div class="acc-container">
        <div class="content"> IH-Tsunamis System (IH-TSUSY) es un Sistema de simulación y notificación de tsunamis en tiempo real basada en la 
detección y notificación de terremotos en cualquier punto del Globo.  http://tsunami.ihcantabria.com/
 El Sistema recibe la información sísmica que, en tiempo real, proporcionan agencias internacionales, como la estadounidense USGS. Con los datos 
captados IH-TSUSY evalúa si el sismo cumple las características necesarias para generar un tsunami, en cuyo caso simula numéricamente su propagación 
y proporciona a través de la app notificaciones y mapas interactivos que contienen diversos datos de interés, como la amplitud (o altura de ola) y 
los tiempos de viaje de la onda desde la zona donde ha sido generada hasta las áreas costeras potencialmente afectadas. En la actualidad la 
aplicación para Android “IH Tsunamis System” ha sido instalada por más de 9000 usuarios y actualmente está operativa en más de 2100 dispositivos en 
todo el mundo (16% USA, 15% Indonesia, 9% Germany, 5% Spain, 5% Brazil). El mayor hándicap del sistema de alerta reside en el tiempo necesario para la simulación del modelo numérico (entre una o dos horas). Por lo tanto, este proyecto analizaría las alternativas (por ejemplo uso de GPUs) y llevaría a cabo las acciones necesarias para diseñar, desarrollar e implementar la alternativa seleccionada en el Sistema IH-Tsusy.   <br><br>
Responsable:Felipe Fernández
<br>Contacto: <b>felipe.fernandez@unican.es</b>
        </div>
        </div>








    	<!-- section 13 -->
        <span class="acc-trigger active"><a href="#">13.- Automated bug triaging system  </a></span>
        <div class="acc-container">
        <div class="content"> Bug classification and triaging is a tedious task in any large software project. 
These task is performed by hand and normally involves the identification of the best assignee, the 
identification of its impact or severity, etc. becoming a bottleneck when the number of bugs that need to be 
triaged is high. Moreover, bug triaging is an essential task as its correctness has a high impact in the whole 
project.
In this proposal the student will scout the state of the art regarding automated bug triaging systems, implementing an automated framework for bug triaging based on deep learning techniques. We will study several public bug trackers, as well as the (private and protected) issue tracker of the EGI.eu European e-Infrastructure.        

 <br><br> 
Responsable:Álvaro López <br>
Contacto: <b>aloga@ifca.unican.es</b>
</div>
        </div>


    	<!-- section 14 -->
        <span class="acc-trigger active"><a href="#">14.- Building a python tool for anonymizing sensitive data  </a></span>
        <div class="acc-container">
        <div class="content"> 

Anonymizing sensitive data is a critical task when dealing with
datasets that contain personal details (like health records, census,
cell towers records, etc.). There are several methods (privacy models)
for anomymizing data (like k-anonimity or l-diversity among many
others).

Although there are tools for anonymizing data (like ARX), Python lacks a
comprehensive anonymization library and tool. In this project we will
build a library for the Python language, implementing the most common
privacy models, so that these methods can be included in a machine
learning pipeline.
 <br><br> 
Responsable:Álvaro López <br>
Contacto: <b>aloga@ifca.unican.es</b>
</div>
        </div>


    




    	<!-- section 15 -->
        <span class="acc-trigger active"><a href="#">15.- Benchmark de infraestructuras de supercomputación mediante el uso de técnicas de machine learning  </a></span>
        <div class="acc-container">
        <div class="content"> 
El uso de infraestructuras de computación de alto rendimiento (HPC) y supercomputadores para el desarrollo de herramientas de machine learning e inteligencia artificial está cada vez más extendido. Por otro lado, el desarrollo continuo de nuevo hardware (procesadores, interconexiones, aceleradores) y software (frameworks y librerías) ha incrementado la heterogeneidad de estos sistemas, siendo dificil su comparación en términos de rendimiento. Los bechmarks existentes fallan en el objetivo de proporcionar una medida coherente y válida que sirva como referencia para aplicaciones de aprendizaje automático e inteligencia artificial. En este proyecto se pretende abordar esta problemática, explorando las diferentes alternativas (como MLPerf) e implementando una batería de tests, basados en aplicaciones de aprendizaje máquina, de forma que sea posible realizar la comparación de sistemas HPC.

Responsable:Álvaro López
<br>Contacto: <b>aloga@ifca.unican.es</b>
        </div>
        </div>


    
   


    	<!-- section 16 -->
        <span class="acc-trigger active"><a href="#">16.-  Técnicas de Deep Learning en astronomía</a></span>
        <div class="acc-container">
        <div class="content">

El observatorio espacial XMM-Newton de la Agencia Europea del Espacio observa regularmente el cielo. Las imágenes producidas son utilizadas para producir catálogos de fuentes astronómicas de rayos X.Sin embargo, algunas de las imágenes presentan regiones que no son apropiadas para la detección de fuentes y deben ser marcadas y excluidas. Hasta ahora, esta tarea se ha venido realizando de manera manual por expertos que examinan las imágenes una a una,seleccionando las áreas defectuosas y creando a su alrededor regiones de exclusión. Recientemente, los enfoques basados en el aprendizaje profundo han presentado el rendimiento de vanguardia en problemas de clasificación de imágenes, debido a su capacidad de autoaprendizaje en la extracción de las características de las imágenes y su capacidad para manejar rápidamente una gran cantidad de datos. Sin embargo, la tarea de detección de objetos excede la tarea de clasificación de imágenes en términos de complejidad. Esta técnica, conocida como segmentación, consiste en crear cuadros delimitadores alrededor de los objetos contenidos en una imagen y clasificar cada uno de sus píxeles. Los desafíos surgen cuando se tiene que tener en cuenta el contexto de toda la imagen,  los objetos pueden tener formas muy diferentes y se carece de suficientes datos de alta resolución. El objeto de este trabajo es utilizar técnicas de Deep Learning para automatizar completamente la selección de las áreas defectuosas de las imágenes producidas por el telescopio XMM-Newton. Bajo el punto de vista de la ciencia de datos estas imágenes presentan muchos desafíos que trasforman este trabajo en algo de especial interés, desde la perspectiva tanto de la astronomía como de la ciencia de datos.        
<br>Contacto: <b>tuccillo@ifca.unican.es</b>

</div>
</div>


    	<!-- section 17 -->
        <span class="acc-trigger active"><a href="#">17.-  Aplicación de técnicas de machine learning para el downscaling estadístico de predicciones estacionales climáticas</a></span>
        <div class="acc-container">
        <div class="content">

El objetivo de la predicción estacional es el de estimar las condiciones climáticas promedio que se darán sobre una región dada en los próximos meses (hasta un año vista). Este tipo de predicciones tiene un gran número de aplicaciones en distintos sectores socio-económicos como la agricultura, la energía, el transporte y la salud, por lo que su uso no ha dejado de aumentar en las últimas décadas. Sin embargo, a diferencia de lo que ocurre con las predicciones meteorológicas a corto y medio plazo, la baja resolución espacial de los modelos numéricos que se utilizan en la predicción estacional (modelos acoplados atmósfera-océano) resulta insuficiente para la mayoría de aplicaciones prácticas (en torno a las decenas de km). Una de las consecuencias directas de esta falta de resolución es la presencia de importante sesgos sistemáticos, que hay que calibrar adecuadamente tomando como referencia datos de observaciones sobre un período suficientemente largo. En este TFM se estudiará el potencial de distintas técnicas de minería de datos vistas durante la asignatura de Data Mining para la regionalización (downscaling en inglés) de las simulaciones de los últimos modelos de predicción estacional, con el objetivo último de obtener predicciones locales bien calibradas. En particular, se analizarán la idoneidad de técnicas sencillas como árboles de clasificación/regresión (CART), así como métodos de ensembles más sofisticados como Random Forest y Gradient Boosting, y se explorará el potencial de diferentes patrones de teleconexión como variables predictoras.       
<br>Contacto: <b>rodrigo.manzanas@unican.es</b>

</div>
</div>



    	<!-- section 18 -->
        <span class="acc-trigger active"><a href="#">18.-  Segmentation in medical imaging (brain tumors)</a></span>
        <div class="acc-container">
        <div class="content">

Segmentation in medical imaging is the delineation of organs and structures of interest. It is often a fundamental step in image analysis pipelines. The student will survey existing literature and implement a machine learning method for segmentation of structures in the provided dataset.
<br>Contacto: <b>drodrig@ifca.unican.es</b>


</div>
</div>


    	<!-- section 19 -->
        <span class="acc-trigger active"><a href="#">19.- Pattern Recognition Algorithm for Dark Matter signals on pixel detectors </a></span>
        <div class="acc-container">
        <div class="content">

DAMIC (DArk Matter In CCDs) Experiment uses a silicon pixel detector capable of tracking ionizing particles as isolated clusters of pixels. The main purpose of the thesis is to develop a pattern recognition algorithm to achieve particle identification. This is motivated by the theory of energy deposition along the particle trajectory within a CCD. The final goal is to investigate the viability of the presented feature model for identification of nuclear recoil due to dark matter interaction with the silicon bulk of the CCD sensor.
<br>Contacto: <b>castello@ifca.unican.es</b>


</div>
</div>


    	<!-- section 20 -->
        <span class="acc-trigger active"><a href="#">20.- Predicción de mercado en función del análisis de historicos de ventas y desarrollo de diseños textiles </a></span>
        <div class="acc-container">
        <div class="content">

<br>Contacto: <b>juanmarcos@tsanta.es</b>


</div>
</div>



    	<!-- section 21 -->
        <span class="acc-trigger active"><a href="#">21.- Integración de Jupyter Notebooks con repositorios de software y datos. </a></span>
        <div class="acc-container">
        <div class="content">
El uso de Jupyter Notebooks para fines científicos está cada vez más extendido gracias a su uso sencillo y a las posibilidades que ofrece de abstraer entornos computacionales complejos. Esto permite la gestión de grandes volúmenes de datos utilizando recursos cloud, por lo que se abre una gran capacidad de integración con estas herramientas. Sin embargo, en ocasiones los usuarios necesitan añadir sus datos manualmente, descargando de distintas fuentes y adecuando los formatos a fines específicos. Este trabajo propone desarrollar un sistema (o notebook) basado en Jupyter que se integre con algún repositorio de datos/software en abierto, como el proporcionado por el CSIC (DIGITAL.CSIC). De este modo, los usuarios podrían desde un único notebook, acceder a los datos disponibles en el repositorio para llevar a cabo su labor científica.El uso de Jupyter Notebooks para fines científicos está cada vez más extendido gracias a su uso sencillo y a las posibilidades que ofrece de abstraer entornos computacionales complejos. Esto permite la gestión de grandes volúmenes de datos utilizando recursos cloud, por lo que se abre una gran capacidad de integración con estas herramientas. Sin embargo, en ocasiones los usuarios necesitan añadir sus datos manualmente, descargando de distintas fuentes y adecuando los formatos a fines específicos. Este trabajo propone desarrollar un sistema (o notebook) basado en Jupyter que se integre con algún repositorio de datos/software en abierto, como el proporcionado por el CSIC (DIGITAL.CSIC). De este modo, los usuarios podrían desde un único notebook, acceder a los datos disponibles en el repositorio para llevar a cabo su labor científica.

<br>Contacto: <b>aguilarf@ifca.unican.es</b>

</div>
</div>

    	<!-- section 22 -->
        <span class="acc-trigger active"><a href="#">22.- Estimación automática de recursos de agua potable utilizando datos abiertos </a></span>
        <div class="acc-container">
        <div class="content">

La información proporcionada por satélites y otras fuentes de datos de teledetección, permite definir índices para estimar ciertas variables medioambientales (humedad, temperatura, vegetación). Uno de ellos es la presencia o no de agua continental. Este TFM propone, utilizando fuente de datos abiertas como las de Copernicus o Landsat además de otras por definir, desarrollar un método para estimar el volumen de agua potable de forma automática.
<br>Contacto: <b>aguilarf@ifca.unican.es</b>


</div>
</div>


    	<!-- section 23 -->
        <span class="acc-trigger active"><a href="#">23. - Deep learning aplicado a la obtención de proyecciones locales de cambio climático en regiones con escasez de datos </a></span>
        <div class="acc-container">
        <div class="content">

El desarrollo de proyecciones regionales de cambio climático es crucial para la evaluación de su impacto y la elaboración de los correspondientes planes de adaptación. Dicha regionalización se aborda actualmente con dos técnicas: estadísticas y dinámicas. En el primer caso, se consideran registros históricos para entrenar los modelos (p.e. knn, regresión, deep learning, etc..), habiendo demostrado los métodos basados en deep learning (p.e. redes de convolución) una gran capacidad predictora para la obtención de proyecciones a escala continental a diferencia de otras técnicas clásicas (p.e. regresión lineal). Sin embargo, la escasez de registros observacionales en ciertas regiones limita la aplicación de técnicas estadísticas para la obtención de proyecciones regionales de cambio climático fiables. De este modo, en este TFM exploraremos la capacidad de extrapolación espacial de modelos estadísticos basados en deep learning, entrenando dichos métodos con registros observados en partes del mundo diferentes a la de aplicación. En particular consideraremos el continente africano como región objetivo, el cual no dispone de una red de registros observacionales de calidad, entrenando los métodos con registros observaciones de otras regiones del globo.
<br>Contacto: <b>bmedina@ifca.unican.es, miturbide@ifca.unican.es</b>


</div>
</div>

   	<!-- section 24 -->
        <span class="acc-trigger active"><a href="#">24. - Cálculo automatizado de la estación de fuegos a escala global mediante técnicas de aprendizaje no supervisado. Aplicaciones para la predicción estacional de incendios. </a></span>
        <div class="acc-container">
        <div class="content">

Partiendo de datos satelitales de actividad de fuegos, este TFM tiene como primer objetivo el cálculo automático de la estación de incendios a escala global, para lo cual se  utilizarán técnicas de aprendizaje no supervisado (clustering). En particular, se estudiará el potencial de las "Gaussian Mixtures" para la caracterización del ciclo anual de incendios a nivel de píxel. Partiendo de esta información, el segundo objetivo del TFM será el desarrollo de un sistema global de alerta temprana de riesgo de incendios. Para ello se estudiarán primero las relaciones existentes entre la actividad de fuegos en las distintas regiones (clusters) del mundo y un conjunto de índices que caracterizan la dinámica del sistema climático a escala planetaria utilizando técnicas de aprendizaje supervisado. A continuación, y haciendo uso de las relaciones encontradas, se explorará el potencial de los modelos climáticos de última generación para la generación de predicciones estacionales (con una antelación de uno a varios meses) de riesgo de incendios.
<br>Contacto: <b>joaquin.bedia@unican.es, rodrigo.manzanas@unican.es</b>


</div>
</div>



  <br/>






	<div class="content_fullwidth">
    <div class="accrodation">
         <p><b>Ofertas TFM 2019-2020</b></p>
         <br/>
    	<!-- section 1 -->
        <span class="acc-trigger active"><a href="#">1.- Análisis de datos del microbioma gastrointestinal</a></span>
        <div class="acc-container">
        <div class="content">
En este proyecto se propone aplicar técnicas de aprendizaje automático y minería de datos para identificar posibles asociaciones entre las especies presentes en la flora intestinal y su cantidad relativa respecto a los principales factores fisiológicos, bioquímicos, metabólicos, nutricionales y deportivos relacionados con los cambios en la composición corporal. El objetivo es encontrar y definir biomarcadores que permitan distinguir entre los variados microbiomas y asociarlos a patologías o estados de salud. La gran diversidad interpersonal de la flora intestinal lo convierte en una tarea complicada para el ser humano, pero potencialmente adecuada para las técnicas de aprendizaje automático. Se usará una batería de análisis genéticos del microbioma intestinal específicamente dirigidos al ámbito del fitness profesional amateur que contiene unos 650000 marcadores y datos asociados (entrenamientos, lesiones, etcétera)
<br>
<br>
Responsable: Cristina Tirnauca 
<br>Contacto: <b>cristina.tirnauca@unican.es</b>
        </div>
        </div>
    	<!-- section 2 -->
        <span class="acc-trigger active"><a href="#">2.- Automatic Data Curation tool</a></span>
        <div class="acc-container">
        <div class="content">
Asegurar no sólo la accesibilidad de los datos, sino también su calidad para que puedan ser reutilizados para obtener información, es un reto al que se enfrentan tanto empresas como disciplinas científicas. Este trabajo desarrollará una herramienta para automatizar procesos para mejorar la calidad de los datos procedentes de fuentes en abierto, aplicando métodos de curación a diferentes conjuntos de datos.
<br>
<br>
Responsable: Fernando Aguilar
<br>Contacto: <b>aguilarf@ifca.unican.es</b>
        </div>
        </div>
    	<!-- section 3 -->
        <span class="acc-trigger active"><a href="#">3.- Cinco estrellas para repositorios de datos en abierto </a></span>
        <div class="acc-container">
        <div class="content">
Tim Berners-Lee, el inventor de la Web e iniciador de los Datos Enlazados (Linked Data), sugirió un esquema de desarrollo de 5 estrellas para Datos Abiertos. Dentro de los distintos tipos de repositorios de datos en abierto disponibles (gubernamentales, científicos, sociales) el nivel de adopción de este esquema es bastante desigual. El trabajo a desarrollar analizará varios repositorios con el fin de ver qué medidas se podrían tomar para conseguir que los datos publicados puedan ser fácilmente reutilizables.
<br>
<br>
Responsable: Fernando Aguilar
<br>Contacto: <b>aguilarf@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 4 -->
        <span class="acc-trigger active"><a href="#">4.- Estimación del número de personas en imágenes mediante muestreo geométrico</a></span>
        <div class="acc-container">
        <div class="content">
Analizaremos la precisión del método CountEm ( countem.unican.es ) de forma similar a lo realizado en el artículo <a>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141868</a> pero con los datos UCF-QNRF - A Large Crowd Counting Data Set <a>http://crcv.ucf.edu/data/ucf-qnrf/</a>      
<br>
<br>
Responsable: Marcos Cruz
<br>Contacto: <b>marcos.cruz@unican.es</b>
        </div>
        </div>

    	<!-- section 5 -->
        <span class="acc-trigger active"><a href="#">5.- Entrenamiento de redes neuronales con muestras sesgadas</a></span>
        <div class="acc-container">
        <div class="content">
En este trabajo se comprobará mediante técnicas de data augmentation si se puede mejorar la respuesta de ANN convencionales en casos en los que las muestras de entrenamiento presenten sesgos en alguna de sus variables.
<br>
<br>
Responsable: Francisco Matorras
<br>Contacto: <b>francisco.matorras@unican.es</b>

        </div>
        </div>


    	<!-- section 6 -->
        <span class="acc-trigger active"><a href="#">6.- Desarrollo de APIs para repositorios científicos</a></span>
        <div class="acc-container">
        <div class="content">
El creciente número de datasets científicos aumenta enormemente las posibilidades de reutilización de datos de calidad. Sin embargo, en ocasiones, los repositorios en los que se alojan no son lo suficientemente potentes para hacer un uso masivo de esos datos disponibles. Este trabajo propondrá y desarrollará APIs o plugins para aumentar las funcionalidades de repositorios científicos cpmo digital CSIC.
<br>
<br>
Responsable: Isabel Bernal
<br>Contacto: <b>isabel.bernal@bib.csic.es</b>

        </div>
        </div>




    	<!-- section 7 -->
        <span class="acc-trigger active"><a href="#">7.- Massive Parallel Machine Learning: evaluation of parallel processing implementations</a></span>
        <div class="acc-container">
        <div class="content">
The term massively parallel processing refers to the coordinated usage of a large number of processors or separate computers to carry out a given task. Generally speaking two kinds of parallelism exist: data and model parallelism. In this work we propose that the student performs a survey and state of the art evaluation of the existing parallel implementations for machine learning frameworks and libraries.
<br>
<br>
Responsable: Álvaro López
<br>Contacto: <b>aloga@ifca.unican.es</b>

        </div>
        </div>

    	<!-- section 8 -->
        <span class="acc-trigger active"><a href="#">8.- Massive Parallel Deep Learning: evaluation of parallel processing implementations</a></span>
        <div class="acc-container">
        <div class="content">
The term massively parallel processing refers to the coordinated usage of a large number of processors or separate computers to carry out a given task. Generally speaking two kinds of parallelism exist: data and model parallelism. In this work we propose that the student performs a survey and state of the art evaluation of the existing parallel implementations for deep learning frameworks and libraries.
<br>
<br>
Responsable: Álvaro López
<br>Contacto: <b>aloga@ifca.unican.es</b>


        </div>
        </div>



    	<!-- section 9 -->
        <span class="acc-trigger active"><a href="#">9.- Selección de predictores para la generación de modelos predictivos de Ciclones Tropicales. </a></span>
        <div class="acc-container">
        <div class="content">
A pesar del gran impacto de los eventos extremos asociados a la ocurrencia de ciclones, tanto en el trópico como en latitudes medias (p.e. Europa), la génesis y el desarrollo de este tipo de eventos depende de factores muy diversos (región, estación del año, etc.) por lo que, de cara a proponer un modelo de predicción, es necesario el desarrollo de algoritmos de selección de variables que permitan la detección de aquellos predictores relevantes para el evento de estudio. En el presente trabajo se propone implementar y validar usando la base de datos de referencia para la WMO, IBTrACS-WMO, un algoritmo de selección de variables basado en grafos que identifique, a partir de un número elevado de posibles predictores, aquellos que den lugar a una mejor modelización de la ocurrencia de estos eventos.
<br>
<br>
Responsable: Sixto Herrera
<br>Contacto: <b>herreras@unican.es</b>
        </div>
        </div>


    	<!-- section 10 -->
        <span class="acc-trigger active"><a href="#">10.- Clustering of Russian Troll Tweets</a></span>
        <div class="acc-container">
        <div class="content">
A data set contaning almost 3 million tweets from accounts associated with the Internet Research Agency has been made available thanks to the work of two professors at Clemson University: Darren Linvill and Patrick Warren. Using advanced social media tracking software, they pulled the tweets from thousands of accounts that Twitter has acknowledged as being associated with the IRA. The student will use unsuprevised learning to explore the dataset and try to find unknown patterns in the tweets.
<br>
<br>
Responsable: David Rodríguez
<br>Contacto: <b>drodrig@ifca.unican.es</b>
        </div>
        </div>

    	<!-- section 11 -->
        <span class="acc-trigger active"><a href="#">11.- Supervised learning for classifying Russian Troll Tweets</a></span>
        <div class="acc-container">
        <div class="content">
A data set contaning almost 3 million tweets from accounts associated with the Internet Research Agency has been made available thanks to the work of two professors at Clemson University: Darren Linvill and Patrick Warren. Using advanced social media tracking software, they pulled the tweets from thousands of accounts that Twitter has acknowledged as being associated with the IRA. The student will use supervised learning to build a classifier that groups the tweets according to the Troll category attributed by the Clemson University researchers (Right Troll, Left Troll, Newsfeed, Hashtag gamer and fearmonger).
<br>
<br>
Responsable:David Rodríguez
<br>Contacto: <b>drodrig@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 12 -->
        <span class="acc-trigger active"><a href="#">12.- Modelos de extremos no estacionarios aplicados al oleaje </a></span>
        <div class="acc-container">
        <div class="content">
En los últimos años, se ha producido un importante avance en la definición de modelos de extremos no estacionarios permitiendo caracterizar la distribución estadística de los extremos (parámetros de localización, escala y forma) condicionada a diversas escalas temporales (estacionalidad, variabilidad interanual, tendencia de largo plazo). El objetivo de este trabajo es desarrollar una librería de funciones de Python para el modelado de series de extremos no estacionarios a partir de modelos lineales multivariados heterocedásticos o a partir de redes neuronales y su aplicación a series temporales de datos de oleaje del reanálisis CSIRO y de satélite.

<br>
<br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>

        </div>
        </div>
    	<!-- section 13 -->
        <span class="acc-trigger active"><a href="#">13.- Clima marítimo de mares de fondo (swells) en las Islas Marshall (Océano Pacífico): zonas de generación y análisis estadístico multivariante </a></span>
        <div class="acc-container">
        <div class="content">
El oleaje que recibe cada isla del Pacífico tropical es el resultado de la suma de energías procedentes de multitud de zonas de generación, pudiendo haber en un instante determinado entre 10 y 15 familias de oleaje. Se requiere de herramientas para caracterizar las zonas de generación y para modelar estadísticamente los eventos de mar de fondo. Para ello, en este trabajo se desarrollarán modelos de seguimiento de swells, técnicas de minería de datos para categorizar las familias de oleaje y técnicas estadísticas multivariadas para modelar la distribución conjunta de los parámetros que representan cada oleaje swell. Las bases de datos procederán del reanálisis global de CSIRO de espectros direccionales de oleaje.

<br>
<br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>

        </div>
        </div>
    	<!-- section 14 -->
        <span class="acc-trigger active"><a href="#">14.- Redes Bayesianas para modelar la cronología del oleaje multivariado a partir de patrones diarios de circulación atmosférica </a></span>
        <div class="acc-container">
        <div class="content">
La técnica de downscaling estadístico basada en patrones sinópticos se está utilizando recientemente para modelar el clima marítimo multivariado. La cronología de las N categorías de los patrones sinópticos  se caracteriza a partir de modelos auto-regresivos logísticos, forzados por covariables climáticas a distintas escalas temporales (estacionalidad, oscilación MJO,  oscilación QBO, oscilación de El Niño, manchas solares). Estas covariables están fuertemente correlacionadas, por lo que es deseable modelar probabilísticamente con una red bayesiana la cronología de los patrones sinópticos condicionado por las covariables mencionadas. Las bases de datos procederán del reanálisis atmosférico CFSR y del reanálisis de oleaje de CSIRO.
<br>
<br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>

        </div>
        </div>




    	<!-- section 15 -->
        <span class="acc-trigger active"><a href="#">15.- Optimización de la simulación numérica del Sistema de Alerta de Tsunamis (IH-Tsusy) </a></span>
        <div class="acc-container">
        <div class="content"> IH-Tsunamis System (IH-TSUSY) es un Sistema de simulación y notificación de tsunamis en tiempo real basada en la 
detección y notificación de terremotos en cualquier punto del Globo.  http://tsunami.ihcantabria.com/
 El Sistema recibe la información sísmica que, en tiempo real, proporcionan agencias internacionales, como la estadounidense USGS. Con los datos 
captados IH-TSUSY evalúa si el sismo cumple las características necesarias para generar un tsunami, en cuyo caso simula numéricamente su propagación 
y proporciona a través de la app notificaciones y mapas interactivos que contienen diversos datos de interés, como la amplitud (o altura de ola) y 
los tiempos de viaje de la onda desde la zona donde ha sido generada hasta las áreas costeras potencialmente afectadas. En la actualidad la 
aplicación para Android “IH Tsunamis System” ha sido instalada por más de 9000 usuarios y actualmente está operativa en más de 2100 dispositivos en 
todo el mundo (16% USA, 15% Indonesia, 9% Germany, 5% Spain, 5% Brazil). El mayor hándicap del sistema de alerta reside en el tiempo necesario para la simulación del modelo numérico (entre una o dos horas). Por lo tanto, este proyecto analizaría las alternativas (por ejemplo uso de GPUs) y llevaría a cabo las acciones necesarias para diseñar, desarrollar e implementar la alternativa seleccionada en el Sistema IH-Tsusy.   <br><br>
Responsable:Felipe Fernández
<br>Contacto: <b>felipe.fernandez@unican.es</b>
        </div>
        </div>





    	<!-- section 16 -->
        <span class="acc-trigger active"><a href="#">16.- Respuesta estructural de edificios históricos a partir de análisis dinámico-estadístico  </a></span>
        <div class="acc-container">
        <div class="content"> 
En este TFM se analizará la respuesta structural de edificios históricos
de Cantabria a partir del modelado de series temporales multivariadas, procedentes de la
monitorización de series temporales de sensores de deformación (desplazamiento e
inclinación) y series de variables meteorológicas (temperatura, velocidad del viento,
humedad). Se utilizarán modelos lineales y no lineales para predecir la deformación de
la estructura a partir de las variables meteorológicas.
<br><br>Material: Blanco et al (2018) An integrated structural health monitoring system for
determining local/global responses of historic masonry buildings, Struct Control Health
Monit. DOI: 10.1002/stc.2196<br><br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>
        </div>
        </div>



    	<!-- section 17 -->
        <span class="acc-trigger active"><a href="#">17.- Automated bug triaging system  </a></span>
        <div class="acc-container">
        <div class="content"> Bug classification and triaging is a tedious task in any large software project. 
These task is performed by hand and normally involves the identification of the best assignee, the 
identification of its impact or severity, etc. becoming a bottleneck when the number of bugs that need to be 
triaged is high. Moreover, bug triaging is an essential task as its correctness has a high impact in the whole 
project.
In this proposal the student will scout the state of the art regarding automated bug triaging systems, implementing an automated framework for bug triaging based on deep learning techniques. We will study several public bug trackers, as well as the (private and protected) issue tracker of the EGI.eu European e-Infrastructure.        

 <br><br> 
Responsable:Álvaro López <br>
Contacto: <b>aloga@ifca.unican.es</b>
</div>
        </div>


    	<!-- section 18 -->
        <span class="acc-trigger active"><a href="#">18.- Building a python tool for anonymizing sensitive data  </a></span>
        <div class="acc-container">
        <div class="content"> 

Anonymizing sensitive data is a critical task when dealing with
datasets that contain personal details (like health records, census,
cell towers records, etc.). There are several methods (privacy models)
for anomymizing data (like k-anonimity or l-diversity among many
others).

Although there are tools for anonymizing data (like ARX), Python lacks a
comprehensive anonymization library and tool. In this project we will
build a library for the Python language, implementing the most common
privacy models, so that these methods can be included in a machine
learning pipeline.
 <br><br> 
Responsable:Álvaro López <br>
Contacto: <b>aloga@ifca.unican.es</b>
</div>
        </div>


    	<!-- section 19 -->
        <span class="acc-trigger active"><a href="#">19.- Generación de una bandera electrónica para playas desatendidas mediante técnicas de machine learning </a></span>
        <div class="acc-container">
        <div class="content"> 
¿Sabías que cada 91 minutos muere ahogada una persona en las playas de Brasil?. Hemos conseguido financiación, a través del programa Copernicus Marine (http://marine.copernicus.eu/), para desarrollar una bandera electrónica que sea accesible por los usuarios finales a través de dispositivos móviles. Puedes acceder a más información en este enlace http://soseas.ihcantabria.com/. Tu labor será ayudarnos en el proceso de diseño, configuración, desarrollo e implementación de técnicas de machine learning aplicadas al cálculo dinámico del riesgo de ahogamiento en playas.   

Responsable:Felipe Fernández

<br>Contacto: <b>felipe.fernandez@unican.es</b>
        </div>
        </div>





    	<!-- section 20 -->
        <span class="acc-trigger active"><a href="#">20.- Modelado de precipitación de ciclones tropicales a partir de datos de satélite  </a></span>
        <div class="acc-container">
        <div class="content"> 

Se combinarán bases de datos de precipitación procedente de satélite (TRMM), junto con trazas históricas de ciclones tropicales (IBTraCS), para desarrollar un modelo empírico de precipitación, utilizando técnicas de clasificación de redes neuronales autoorganizativas.
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>
        </div>
        </div>



    	<!-- section 21 -->
        <span class="acc-trigger active"><a href="#">21.- Series temporales numéricas I </a></span>
        <div class="acc-container">
        <div class="content"> 
Emprender un proyecto “end to end" de Data Science en el marco teórico representado por las series temporales numéricas. Paradigma de aprendizaje supervisado para elaborar predicciones sobre series temporales numéricas:
<br>Análisis de series temporales numéricas. EDA (“exploratory data
analysis”), estacionariedad, tendencia, estacionalidad y
modelado de componentes irregulares.
<br>Series temporales numéricas univariadas (SIMO: “single input
multiple output”) y multivariadas (MIMO: “multiple input multiple
output”)
<br>Enfoque directo (“batch data”) y recursivo (“online data”).
<br>Modelos lineales y no lineales, abierto a la creatividad generada por alumno y tutores de prácticas/TFM.
<br>Contacto: <b>lloret@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 22 -->
        <span class="acc-trigger active"><a href="#">22.- Series temporales numéricas II </a></span>
        <div class="acc-container">
        <div class="content"> 
Emprender un proyecto ent to end" de Data Science en el marco teórico representado por las series temporales numéricas.
<br>Paradigma de aprendizaje no supervisado para elaborar sistemas de
reconocimiento de patrones y anomalías.
<br>Análisis de series temporales numéricas. EDA (“exploratory data
analysis”), estacionariedad, tendencia, estacionalidad y
modelado de componentes irregulares.
<br>Series temporales numéricas univariadas (SIMO: “single input
multiple output”) y multivariadas (MIMO: “multiple input multiple
output”)
<br>Exploración del estado del arte en el clustering de perfiles de
series temporales numéricas.
<br>Detección de patrones y elaboración de respuestas automáticas,
desde una alerta a una escritura en un plc como respuesta. i.e
una previsión de aumento de temperatura puede provocar como
respuesta un apagado preventivo en algún equipo.
<br>Detección de fraude en el campo de las “utilities”. Se entiende
este problema como un problema no supervisado no balanceado
(a menudo).

<br>Contacto: <b>lloret@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 23 -->
        <span class="acc-trigger active"><a href="#">23.- Natural language processing </a></span>
        <div class="acc-container">
        <div class="content"> 
Emprender un proyecto “ent to end" de Data Science en el marco del
procesamiento de lenguaje natural (NLP). Comprender el desarrollo de NLP y
conocer las ideas que puede aportar al negocio. En este sentido hemos
postulado dos ideas básicas que pueden ser extendidas y/o modificadas.
<br> Elaboración de un chatbot encargado de canalizar las primeras fases de
interacción cliente-suministrador estableciendo respuestas automáticas
para preguntas tipo. Es decir, generar una capa de soporte al cliente
administrada por el chatbot.
<br>Nuestro software requiere y posee un buscador de señales y distintos
activos. En este sentido queremos avanzar en este campo y generar un
pequeño sistema QA (“question answering”) que permita realizar estas
búsquedas en lenguaje natural. Extendible para un sistema de “speech
recognition”. i.e: Si cierta búsqueda en el buscador se resume a
elaboración de querys tipo SQL tratar de convertir nuestro buscador en
un intérprete “NL to SQL”.
<br>Estas son las ideas iniciales a trabajar en este campo pero se está
abierto a extender o modificar éstas en relación a lo que trataremos las
tres partes.
<br>Contacto: <b>lloret@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 25 -->
        <span class="acc-trigger active"><a href="#">25.- Nowcasting de precipitación con técnicas de deep learning </a></span>
        <div class="acc-container">
        <div class="content"> 

Existen diferentes metodologías para realizar predicciones de muy corto plazo (nowcasting) de precipitación a partir de datos observados en las últimas horas. Para ello, se utilizan principalmente radares meteorológicos y técnicas de procesamiento de imagen que implementan algunas restricciones dadas por las características de la distribución espacial de la precipitación. Este TFM pretende explorar la utilización de técnicas de deep learning (por ejemplo las redes con arquitectura Long short-term memory) para predecir patrones de precipitación a muy corto plazo así como su comparación con otras técnicas clásicas.
<br>Contacto: <b>daniel@predictia.es</b>
        </div>
        </div>


    	<!-- section 26 -->
        <span class="acc-trigger active"><a href="#">26.-  Técnicas de Deep Learning en astronomía</a></span>
        <div class="acc-container">
        <div class="content">

El observatorio espacial XMM-Newton de la Agencia Europea del Espacio observa regularmente el cielo. Las imágenes producidas son utilizadas para producir catálogos de fuentes astronómicas de rayos X.Sin embargo, algunas de las imágenes presentan regiones que no son apropiadas para la detección de fuentes y deben ser marcadas y excluidas. Hasta ahora, esta tarea se ha venido realizando de manera manual por expertos que examinan las imágenes una a una,seleccionando las áreas defectuosas y creando a su alrededor regiones de exclusión. Recientemente, los enfoques basados en el aprendizaje profundo han presentado el rendimiento de vanguardia en problemas de clasificación de imágenes, debido a su capacidad de autoaprendizaje en la extracción de las características de las imágenes y su capacidad para manejar rápidamente una gran cantidad de datos. Sin embargo, la tarea de detección de objetos excede la tarea de clasificación de imágenes en términos de complejidad. Esta técnica, conocida como segmentación, consiste en crear cuadros delimitadores alrededor de los objetos contenidos en una imagen y clasificar cada uno de sus píxeles. Los desafíos surgen cuando se tiene que tener en cuenta el contexto de toda la imagen,  los objetos pueden tener formas muy diferentes y se carece de suficientes datos de alta resolución. El objeto de este trabajo es utilizar técnicas de Deep Learning para automatizar completamente la selección de las áreas defectuosas de las imágenes producidas por el telescopio XMM-Newton. Bajo el punto de vista de la ciencia de datos estas imágenes presentan muchos desafíos que trasforman este trabajo en algo de especial interés, desde la perspectiva tanto de la astronomía como de la ciencia de datos.        
<br>Contacto: <b>tuccillo@ifca.unican.es</b>

</div>
</div>


    	<!-- section 27 -->
        <span class="acc-trigger active"><a href="#">27.-  Mejora de las predicciones estacionales climáticas mediante el uso de técnicas de minería de datos</a></span>
        <div class="acc-container">
        <div class="content">

A diferencia de la predicción meteorológica a corto y medio plazo, la predicción estacional no trata de estimar la temperatura o precipitación para un instante de tiempo concreto en unos pocos días, sino las condiciones climáticas promedio para los próximos meses (por ejemplo, en forma de anomalías basadas en terciles: frío/normal/cálido, seco/normal/húmedo). Las predicciones estacionales tiene un gran número de aplicaciones y ayudan a la toma de decisiones en distintos sectores socio-económicos como la agricultura, la energía, el transporte, la salud y la hidrología, por lo que su uso no ha dejado de aumentar en las últimas décadas. Sin embargo, a diferencia de lo que ocurre con las predicciones meteorológicas a corto y medio plazo, la fiabilidad de las predicciones estacionales se restringe a ciertas ventanas de oportunidad (es decir, a ciertas regiones del mundo y momentos del año), que hay que identificar adecuadamente. Además, la baja resolución espacial de los modelos numéricos que se utilizan para este tipo de predicción (modelos acoplados atmósfera-océano) resulta insuficiente para la mayoría de aplicaciones prácticas (en torno a los 100 km). Una de las consecuencias directas de esta falta de resolución es la presencia de importante sesgos sistemáticos en estos modelos, que hay que calibrar adecuadamente para que sus salidas crudas tengan sentido. Para solventar estas limitaciones, en este TFM se estudiará el potencial de distintas técnicas de minería de datos vistas durante la asignatura de Data Mining para la regionalización (downscaling en inglés) de las simulaciones crudas de los modelos numéricos del clima, con el objetivo último de obtener predicciones locales y bien calibradas. En particular, se analizarán la idoneidad de técnicas sencillas como árboles de clasificación/regresión (CART), así como métodos de ensembles más sofisticados como Random Forest, y se explorará el potencial de diferentes patrones de teleconexión como predictores para los modelos ajustados. Además, los resultados obtenidos para estas técnicas serán puestas en contexto con aquellos obtenidos por otras técnicas más clásicas que se han venido utilizadno tradicionalmente para el mismo fin (por ejemplo, k-NN y GLMs).
<br>Contacto: <b>rodrigo.manzanas@unican.es</b>


</div>
</div>


    	<!-- section 28 -->
        <span class="acc-trigger active"><a href="#">28.-  Segmentation in medical imaging (brain tumors)</a></span>
        <div class="acc-container">
        <div class="content">

Segmentation in medical imaging is the delineation of organs and structures of interest. It is often a fundamental step in image analysis pipelines. The student will survey existing literature and implement a machine learning method for segmentation of structures in the provided dataset.
<br>Contacto: <b>drodrig@ifca.unican.es</b>


</div>
</div>


    	<!-- section 29 -->
        <span class="acc-trigger active"><a href="#">29.- Pattern Recognition Algorithm for Dark Matter signals on pixel detectors </a></span>
        <div class="acc-container">
        <div class="content">

DAMIC (DArk Matter In CCDs) Experiment uses a silicon pixel detector capable of tracking ionizing particles as isolated clusters of pixels. The main purpose of the thesis is to develop a pattern recognition algorithm to achieve particle identification. This is motivated by the theory of energy deposition along the particle trajectory within a CCD. The final goal is to investigate the viability of the presented feature model for identification of nuclear recoil due to dark matter interaction with the silicon bulk of the CCD sensor.
<br>Contacto: <b>castello@ifca.unican.es</b>


</div>
</div>


    	<!-- section 30 -->
        <span class="acc-trigger active"><a href="#">30.- Predicción de mercado en función del análisis de historicos de ventas y desarrollo de diseños textiles </a></span>
        <div class="acc-container">
        <div class="content">

<br>Contacto: <b>juanmarcos@tsanta.es</b>


</div>
</div>



    	<!-- section 31 -->
        <span class="acc-trigger active"><a href="#">31.- Integración de Jupyter Notebooks con repositorios de software y datos. </a></span>
        <div class="acc-container">
        <div class="content">
El uso de Jupyter Notebooks para fines científicos está cada vez más extendido gracias a su uso sencillo y a las posibilidades que ofrece de abstraer entornos computacionales complejos. Esto permite la gestión de grandes volúmenes de datos utilizando recursos cloud, por lo que se abre una gran capacidad de integración con estas herramientas. Sin embargo, en ocasiones los usuarios necesitan añadir sus datos manualmente, descargando de distintas fuentes y adecuando los formatos a fines específicos. Este trabajo propone desarrollar un sistema (o notebook) basado en Jupyter que se integre con algún repositorio de datos/software en abierto, como el proporcionado por el CSIC (DIGITAL.CSIC). De este modo, los usuarios podrían desde un único notebook, acceder a los datos disponibles en el repositorio para llevar a cabo su labor científica.El uso de Jupyter Notebooks para fines científicos está cada vez más extendido gracias a su uso sencillo y a las posibilidades que ofrece de abstraer entornos computacionales complejos. Esto permite la gestión de grandes volúmenes de datos utilizando recursos cloud, por lo que se abre una gran capacidad de integración con estas herramientas. Sin embargo, en ocasiones los usuarios necesitan añadir sus datos manualmente, descargando de distintas fuentes y adecuando los formatos a fines específicos. Este trabajo propone desarrollar un sistema (o notebook) basado en Jupyter que se integre con algún repositorio de datos/software en abierto, como el proporcionado por el CSIC (DIGITAL.CSIC). De este modo, los usuarios podrían desde un único notebook, acceder a los datos disponibles en el repositorio para llevar a cabo su labor científica.

<br>Contacto: <b>aguilarf@ifca.unican.es</b>

</div>
</div>

    	<!-- section 32 -->
        <span class="acc-trigger active"><a href="#">32.- Estimación automática de recursos de agua potable utilizando datos abiertos </a></span>
        <div class="acc-container">
        <div class="content">

La información proporcionada por satélites y otras fuentes de datos de teledetección, permite definir índices para estimar ciertas variables medioambientales (humedad, temperatura, vegetación). Uno de ellos es la presencia o no de agua continental. Este TFM propone, utilizando fuente de datos abiertas como las de Copernicus o Landsat además de otras por definir, desarrollar un método para estimar el volumen de agua potable de forma automática.
<br>Contacto: <b>aguilarf@ifca.unican.es</b>


</div>
</div>


    	<!-- section 33 -->
        <span class="acc-trigger active"><a href="#">33. - Deep learning aplicado a la obtención de proyecciones locales de cambio climático en regiones con escasez de datos </a></span>
        <div class="acc-container">
        <div class="content">

El desarrollo de proyecciones regionales de cambio climático es crucial para la evaluación de su impacto y la elaboración de los correspondientes planes de adaptación. Dicha regionalización se aborda actualmente con dos técnicas: estadísticas y dinámicas. En el primer caso, se consideran registros históricos para entrenar los modelos (p.e. knn, regresión, deep learning, etc..), habiendo demostrado los métodos basados en deep learning (p.e. redes de convolución) una gran capacidad predictora para la obtención de proyecciones a escala continental a diferencia de otras técnicas clásicas (p.e. regresión lineal). Sin embargo, la escasez de registros observacionales en ciertas regiones limita la aplicación de técnicas estadísticas para la obtención de proyecciones regionales de cambio climático fiables. De este modo, en este TFM exploraremos la capacidad de extrapolación espacial de modelos estadísticos basados en deep learning, entrenando dichos métodos con registros observados en partes del mundo diferentes a la de aplicación. En particular consideraremos el continente africano como región objetivo, el cual no dispone de una red de registros observacionales de calidad, entrenando los métodos con registros observaciones de otras regiones del globo.
<br>Contacto: <b>bmedina@ifca.unican.es, miturbide@ifca.unican.es</b>


</div>
</div>


  <br/>







	<div class="content_fullwidth">
    <div class="accrodation">
         <p><b>Ofertas TFM 2018-2019</b></p>
         <br/>
    	<!-- section 1 -->
        <span class="acc-trigger active"><a href="#">1.- Análisis de datos del microbioma gastrointestinal</a></span>
        <div class="acc-container">
        <div class="content">
En este proyecto se propone aplicar técnicas de aprendizaje automático y minería de datos para identificar posibles asociaciones entre las especies presentes en la flora intestinal y su cantidad relativa respecto a los principales factores fisiológicos, bioquímicos, metabólicos, nutricionales y deportivos relacionados con los cambios en la composición corporal. El objetivo es encontrar y definir biomarcadores que permitan distinguir entre los variados microbiomas y asociarlos a patologías o estados de salud. La gran diversidad interpersonal de la flora intestinal lo convierte en una tarea complicada para el ser humano, pero potencialmente adecuada para las técnicas de aprendizaje automático. Se usará una batería de análisis genéticos del microbioma intestinal específicamente dirigidos al ámbito del fitness profesional amateur que contiene unos 650000 marcadores y datos asociados (entrenamientos, lesiones, etcétera)
<br>
<br>
Responsable: Cristina Tirnauca 
<br>Contacto: <b>cristina.tirnauca@unican.es</b>
        </div>
        </div>
    	<!-- section 2 -->
        <span class="acc-trigger active"><a href="#">2.- Automatic Data Curation tool</a></span>
        <div class="acc-container">
        <div class="content">
Asegurar no sólo la accesibilidad de los datos, sino también su calidad para que puedan ser reutilizados para obtener información, es un reto al que se enfrentan tanto empresas como disciplinas científicas. Este trabajo desarrollará una herramienta para automatizar procesos para mejorar la calidad de los datos procedentes de fuentes en abierto, aplicando métodos de curación a diferentes conjuntos de datos.
<br>
<br>
Responsable: Fernando Aguilar
<br>Contacto: <b>aguilarf@ifca.unican.es</b>
        </div>
        </div>
    	<!-- section 3 -->
        <span class="acc-trigger active"><a href="#">3.- Cinco estrellas para repositorios de datos en abierto </a></span>
        <div class="acc-container">
        <div class="content">
Tim Berners-Lee, el inventor de la Web e iniciador de los Datos Enlazados (Linked Data), sugirió un esquema de desarrollo de 5 estrellas para Datos Abiertos. Dentro de los distintos tipos de repositorios de datos en abierto disponibles (gubernamentales, científicos, sociales) el nivel de adopción de este esquema es bastante desigual. El trabajo a desarrollar analizará varios repositorios con el fin de ver qué medidas se podrían tomar para conseguir que los datos publicados puedan ser fácilmente reutilizables.
<br>
<br>
Responsable: Fernando Aguilar
<br>Contacto: <b>aguilarf@ifca.unican.es</b>
        </div>
        </div>

    	<!-- section 4 -->
        <span class="acc-trigger active"><a href="#">4.- Identificación de las variables relevantes en la identificación de mutaciones somáticas en datos de secuenciación masiva de tumores. </a></span>
        <div class="acc-container">
        <div class="content">

Las nuevas técnicas de secuenciación masiva han aumentado muy significativamente la cantidad de secuencia que se puede generar de las muestras tumorales humanas mejorando la identificación de mutaciones responsables de la patología. Sin embargo las características intrínsecas de los datos generados por estas tecnologías (alta redundancia, secuencias cortas, errores en la lectura, etc.) provocan que la identificación de mutaciones sea complicada. No existe todavía un estudio sobre el peso que tiene cada una de las variables presentes en los datos (calidad de secuencia o de alineamiento, diferencias muestra tumor-normal, cobertura, contexto de secuencia, etc.) en la discriminación de mutaciones reales y falsos positivos. En el presente trabajo se propone recolectar un gran número de variables de una colección de mutaciones validadas y realizar estudios, por ejemplo mediante análisis de componentes principales, que variable o combinación de variables es más eficaz en la identificación de las mutaciones reales.        
<br>
<br>
Responsable: Ignacio Varela
<br>Contacto: <b>ignacio.varela@unican.es</b>
        </div>
        </div>

    	<!-- section 5 -->
        <span class="acc-trigger active"><a href="#">5.- Estimación del número de personas en imágenes mediante muestreo geométrico</a></span>
        <div class="acc-container">
        <div class="content">
Analizaremos la precisión del método CountEm ( countem.unican.es ) de forma similar a lo realizado en el artículo <a>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141868</a> pero con los datos UCF-QNRF - A Large Crowd Counting Data Set <a>http://crcv.ucf.edu/data/ucf-qnrf/</a>      
<br>
<br>
Responsable: Marcos Cruz
<br>Contacto: <b>marcos.cruz@unican.es</b>
        </div>
        </div>

    	<!-- section 6 -->
        <span class="acc-trigger active"><a href="#">6.- Entrenamiento de redes neuronales con muestras sesgadas</a></span>
        <div class="acc-container">
        <div class="content">
En este trabajo se comprobará mediante técnicas de data augmentation si se puede mejorar la respuesta de ANN convencionales en casos en los que las muestras de entrenamiento presenten sesgos en alguna de sus variables.
<br>
<br>
Responsable: Francisco Matorras
<br>Contacto: <b>francisco.matorras@unican.es</b>

        </div>
        </div>


    	<!-- section 7 -->
        <span class="acc-trigger active"><a href="#">7.- Desarrollo de APIs para repositorios científicos</a></span>
        <div class="acc-container">
        <div class="content">
El creciente número de datasets científicos aumenta enormemente las posibilidades de reutilización de datos de calidad. Sin embargo, en ocasiones, los repositorios en los que se alojan no son lo suficientemente potentes para hacer un uso masivo de esos datos disponibles. Este trabajo propondrá y desarrollará APIs o plugins para aumentar las funcionalidades de repositorios científicos cpmo digital CSIC.
<br>
<br>
Responsable: Isabel Bernal
<br>Contacto: <b>isabel.bernal@bib.csic.es</b>

        </div>
        </div>


        <!-- section 8 -->
        <span class="acc-trigger active"><a href="#">8.- <strike>Visualización de datos de satélite en 3D</strike> [ASIGNADO] </a></span>
        <div class="acc-container">
        <div class="content">
Las agencias espaciales internacionales como la NASA o la ESA producen cada año PBs de datos de satélite, accesibles para cualquier científico o ciudadano i$
<br>
<br>
Responsable: Fernando Aguilar
<br>Contacto: <b>aguilarf@ifca.unican.es</b>

        </div>
        </div>



    	<!-- section 9 -->
        <span class="acc-trigger active"><a href="#">9.- Massive Parallel Machine Learning: evaluation of parallel processing implementations</a></span>
        <div class="acc-container">
        <div class="content">
The term massively parallel processing refers to the coordinated usage of a large number of processors or separate computers to carry out a given task. Generally speaking two kinds of parallelism exist: data and model parallelism. In this work we propose that the student performs a survey and state of the art evaluation of the existing parallel implementations for machine learning frameworks and libraries.
<br>
<br>
Responsable: Álvaro López
<br>Contacto: <b>aloga@ifca.unican.es</b>

        </div>
        </div>

    	<!-- section 10 -->
        <span class="acc-trigger active"><a href="#">10.- Massive Parallel Deep Learning: evaluation of parallel processing implementations</a></span>
        <div class="acc-container">
        <div class="content">
The term massively parallel processing refers to the coordinated usage of a large number of processors or separate computers to carry out a given task. Generally speaking two kinds of parallelism exist: data and model parallelism. In this work we propose that the student performs a survey and state of the art evaluation of the existing parallel implementations for deep learning frameworks and libraries.
<br>
<br>
Responsable: Álvaro López
<br>Contacto: <b>aloga@ifca.unican.es</b>


        </div>
        </div>

 <!-- section 11 -->
        <span class="acc-trigger active"><a href="#">11.- <strike>Machine learning for medical imaging segmentation</strike> [ASIGNADO]</a></span>
        <div class="acc-container">
        <div class="content">
Segmentation in medical imaging is the delineation of organs and structures of interest. It is often a fundatmental step in image analysis pipelines. The st$
<br>
<br>
Responsable: David Rodríguez
<br>Contacto: <b>drodrig@ifca.unican.es</b>
        </div>
        </div>



        <!-- section 12 -->
        <span class="acc-trigger active"><a href="#">12.- <strike>Clasificación y predicción de ciclones con técnicas de minería de datos </strike> [ASIGNAD$
        <div class="acc-container">
        <div class="content">
El gran impacto socio-económico de los eventos meteorológicos extremos han dado lugar a la aplicación de técnicas muy diversas para mejorar tanto su predicc$
<br>
<br>
Responsable: Sixto Herrera
<br>Contacto: <b>herreras@unican.es</b>
        </div>
        </div>



    	<!-- section 13 -->
        <span class="acc-trigger active"><a href="#">13.- Selección de predictores para la generación de modelos predictivos de Ciclones Tropicales. </a></span>
        <div class="acc-container">
        <div class="content">
A pesar del gran impacto de los eventos extremos asociados a la ocurrencia de ciclones, tanto en el trópico como en latitudes medias (p.e. Europa), la génesis y el desarrollo de este tipo de eventos depende de factores muy diversos (región, estación del año, etc.) por lo que, de cara a proponer un modelo de predicción, es necesario el desarrollo de algoritmos de selección de variables que permitan la detección de aquellos predictores relevantes para el evento de estudio. En el presente trabajo se propone implementar y validar usando la base de datos de referencia para la WMO, IBTrACS-WMO, un algoritmo de selección de variables basado en grafos que identifique, a partir de un número elevado de posibles predictores, aquellos que den lugar a una mejor modelización de la ocurrencia de estos eventos.
<br>
<br>
Responsable: Sixto Herrera
<br>Contacto: <b>herreras@unican.es</b>
        </div>
        </div>

        <!-- section 14 -->
        <span class="acc-trigger active"><a href="#">14.- <strike>Sentiment analysis in Twitter using Deep Learning </strike>  [ASIGNADO]</a></span>
        <div class="acc-container">
        <div class="content">
Sentiment analysis (aka opinion mining) refers to the study of emotional and subjective information in texts (or other media). The performance of this task $
<br>
<br>
Responsable: David Rodríguez
<br>Contacto: <b>drodrig@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 15 -->
        <span class="acc-trigger active"><a href="#">15.- Clustering of Russian Troll Tweets</a></span>
        <div class="acc-container">
        <div class="content">
A data set contaning almost 3 million tweets from accounts associated with the Internet Research Agency has been made available thanks to the work of two professors at Clemson University: Darren Linvill and Patrick Warren. Using advanced social media tracking software, they pulled the tweets from thousands of accounts that Twitter has acknowledged as being associated with the IRA. The student will use unsuprevised learning to explore the dataset and try to find unknown patterns in the tweets.
<br>
<br>
Responsable: David Rodríguez
<br>Contacto: <b>drodrig@ifca.unican.es</b>
        </div>
        </div>

    	<!-- section 16 -->
        <span class="acc-trigger active"><a href="#">16.- Supervised learning for classifying Russian Troll Tweets</a></span>
        <div class="acc-container">
        <div class="content">
A data set contaning almost 3 million tweets from accounts associated with the Internet Research Agency has been made available thanks to the work of two professors at Clemson University: Darren Linvill and Patrick Warren. Using advanced social media tracking software, they pulled the tweets from thousands of accounts that Twitter has acknowledged as being associated with the IRA. The student will use supervised learning to build a classifier that groups the tweets according to the Troll category attributed by the Clemson University researchers (Right Troll, Left Troll, Newsfeed, Hashtag gamer and fearmonger).
<br>
<br>
Responsable:David Rodríguez
<br>Contacto: <b>drodrig@ifca.unican.es</b>
        </div>
        </div>


    	<!-- section 17 -->
        <span class="acc-trigger active"><a href="#"><strike>17.- Análisis de datos de dispositivos deportivos</strike> [ASIGNADO]</a></span>
        <div class="acc-container">
        <div class="content">
En la actualidad, es muy común hacer deporte con dispositivos que registran numerosas variables de carácter físico, fisiológico o deportivo (posición gps, tiempo, altura, frecuencia cardíaca, cadencia...) y posteriormente se almacenan en formatos estandarizados fit, gpx, tcx. El trabajo plantea entender estos formatos para el desarrollo de una pequeña aplicación que permita realizar análisis estadísticos sencillos sobre estos datos.
<br>
<br>
Responsable:Francisco Matorras
<br>Contacto: <b>francisco.matorras@unican.es</b>

        </div>
        </div>
    	<!-- section 18 -->
        <span class="acc-trigger active"><a href="#">18.- <strike> Cuantificación de la incertidumbre en la predicción espacio-temporal a corto plazo con bayesian deep learning</strike> [ASIGNADO]</a></span>
        <div class="acc-container">
        <div class="content">
La tarea de predecir es comunmente una tarea probabilística (a menos que el sistema se rija por leyes determinísticas). Al ser probabilística, las predicciones vienen con una incertidumbre asociada que indican el grado de confianza en la predicción. En la mayoría de estudios, los modelos de predicción se limitan a proveer la predicción (p.e., la temperatura dentro de 2 días va a ser de 25ºC), obviando la importancia que tiene también proveer la incertidumbre asociada a la predicción para una mejor toma de decisiones  (p.e., la temperatura dentro de 2 días va a ser de 25ºC al 20% de probabilidad). Concretamente en [1], se hace una predicción espacio-temporal para predecir la precipitación a menos de 6 horas (nowcasting) mediante deep learning y obvian la incertidumbre asociada a dichas predicciones. El objetivo de este TFM es cuantificar y caracterizar la incertidumbre asociada al problema del nowcasting mediante la maquinaria del bayesian deep learning.
<br><br>
Referencias:<br>
Shi, Xingjian, et al. Deep learning for precipitation nowcasting: A benchmark and a new model. Advances in Neural Information Processing Systems. 2017.
<br>
<br>
Responsable:Jorge Baño
<br>Contacto: <b>bmedina@ifca.unican.es</b>

        </div>
        </div>
    	<!-- section 19 -->
        <span class="acc-trigger active"><a href="#">19.- Relaciones espacio-temporales de patrones meteorológicos entre el El Niño y el resto del mundo con deep learning</a></span>
        <div class="acc-container">
        <div class="content">
Las redes neuronales son reconocidas por su capacidad para extraer patrones de los datos. Las neuronas de las redes neuronales se agrupan en capas definiendo la arquitectura de la red. Un tipo especial de arquitectura, llamado autoencoder, extrae patrones entre las variables de entrada y las representa en su capa más intermedia. En este artículo [1], utilizan un autoencoder para descubrir las relaciones existentes entre el flujo radiativo en la cima de la atmósfera y la temperatura en la superficie. La idea en este trabajo es realizar el mismo estudio que en [1], pero buscando los relaciones entre la temperatura del mar en el Pacífico Ecuatorial (que caracteriza el fenómeno de El Niño) y otras variables meteorológicas a nivel mundial, (procesos conocido como teleconexiones climáticas).
<br>
<br>
Referencias:<br>
Anderson, Charles, et al. Discovering Spatial and Temporal Patterns in Climate Data Using Deep Learning. 5th International Workshop on Climate Informatics, NCAR Mesa lab, Boulder, CO. 2015.
<br>
<br>
Responsable:Jorge Baño
<br>Contacto: <b>bmedina@ifca.unican.es</b>

        </div>
        </div>
    	<!-- section 20 -->
        <span class="acc-trigger active"><a href="#">20.- <strike> Aplicación de técnicas de machine learning para el downscaling estadístico de simulaciones climáticas</strike> [ASIGNADO]</a></span>
        <div class="acc-container">
        <div class="content">
Los Modelos de Circulación General (GCM, por sus siglas en inglés) son las herramientas utilizadas hoy en día para la simulación del clima en las diferentes escalas temporales, desde la predicción a corto plazo (3-5 días vista) hasta las proyecciones de cambio climático (hasta final de siglo). Debido a ciertas limitaciones físicas y a su alto coste computacional, la resolución espacial de los GCM actuales todavía es insuficiente (del orden de los 100 km en el caso de proyecciones de cambio climático) para un gran número de aplicaciones prácticas. Para ayudar a solventar esta limitación se ha desarrollado en las últimas décadas una extensa batería de técnicas de reducción de escala (o downscaling). De entre ellas, las técnicas de downscaling estadístico tratan de inferir relaciones estadísticas/empíricas entre las simulaciones de baja resolución de los GCM y las observaciones locales/puntuales disponibles para un período histórico. Una vez obtenidas, estas relaciones se utilizan para trasladar las simulaciones futuras de los GCM al correspondiente nivel local/puntual. Las distintas técnicas de downscaling estadístico se han clasificado tradicionalmente en tres grandes familias: funciones de transferencia, tipos de tiempo y generadores de tiempo.
En el marco de la iniciativa europea VALUE (<a>http://www.value-cost.eu/</a>) –cuyo objetivo es el de comparar diferentes estrategias de downscaling para el estudio del cambio climático– han presentado recientemente la intercomparación de métodos de dowscaling estadístico más extensa y rigurosa hasta la fecha. En concreto, en este trabajo se analizan más de 50 técnicas (que cubren las tres grandes familias anteriormente mencionadas) sobre 86 estaciones de temperatura y precipitación repartidas por toda Europa. El objetivo de este TFM es extender este trabajo probando distintas técnicas de machine learning que raramente han sido utilizadas hasta el momento para el downscaling estadístico en el contexto del clima, en particular random forests y métodos de ensembles.
<br>
<br>
Referencias:<br>
Gutiérrez J.M. et al. (2018) An intercomparison of a large ensemble of statistical downscaling methods over Europe: Results from the VALUE perfect predictor crossvalidation experiment. International Journal of Climatology pp 1-36, DOI 10.1002/joc.5462
<br>
<br>
Responsable:Rodrigo Manzanas
<br>Contacto: <b>rmanzanas@ifca.unican.es</b>

        </div>
        </div>
    	<!-- section 21 -->
        <span class="acc-trigger active"><a href="#">21.- Modelos de extremos no estacionarios aplicados al oleaje </a></span>
        <div class="acc-container">
        <div class="content">
En los últimos años, se ha producido un importante avance en la definición de modelos de extremos no estacionarios permitiendo caracterizar la distribución estadística de los extremos (parámetros de localización, escala y forma) condicionada a diversas escalas temporales (estacionalidad, variabilidad interanual, tendencia de largo plazo). El objetivo de este trabajo es desarrollar una librería de funciones de Python para el modelado de series de extremos no estacionarios a partir de modelos lineales multivariados heterocedásticos o a partir de redes neuronales y su aplicación a series temporales de datos de oleaje del reanálisis CSIRO y de satélite.

<br>
<br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>

        </div>
        </div>
    	<!-- section 22 -->
        <span class="acc-trigger active"><a href="#">22.- Clima marítimo de mares de fondo (swells) en las Islas Marshall (Océano Pacífico): zonas de generación y análisis estadístico multivariante </a></span>
        <div class="acc-container">
        <div class="content">
El oleaje que recibe cada isla del Pacífico tropical es el resultado de la suma de energías procedentes de multitud de zonas de generación, pudiendo haber en un instante determinado entre 10 y 15 familias de oleaje. Se requiere de herramientas para caracterizar las zonas de generación y para modelar estadísticamente los eventos de mar de fondo. Para ello, en este trabajo se desarrollarán modelos de seguimiento de swells, técnicas de minería de datos para categorizar las familias de oleaje y técnicas estadísticas multivariadas para modelar la distribución conjunta de los parámetros que representan cada oleaje swell. Las bases de datos procederán del reanálisis global de CSIRO de espectros direccionales de oleaje.

<br>
<br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>

        </div>
        </div>
    	<!-- section 23 -->
        <span class="acc-trigger active"><a href="#">23.- Redes Bayesianas para modelar la cronología del oleaje multivariado a partir de patrones diarios de circulación atmosférica </a></span>
        <div class="acc-container">
        <div class="content">
La técnica de downscaling estadístico basada en patrones sinópticos se está utilizando recientemente para modelar el clima marítimo multivariado. La cronología de las N categorías de los patrones sinópticos  se caracteriza a partir de modelos auto-regresivos logísticos, forzados por covariables climáticas a distintas escalas temporales (estacionalidad, oscilación MJO,  oscilación QBO, oscilación de El Niño, manchas solares). Estas covariables están fuertemente correlacionadas, por lo que es deseable modelar probabilísticamente con una red bayesiana la cronología de los patrones sinópticos condicionado por las covariables mencionadas. Las bases de datos procederán del reanálisis atmosférico CFSR y del reanálisis de oleaje de CSIRO.
<br>
<br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>

        </div>
        </div>


    	<!-- section 24 -->
        <span class="acc-trigger active"><a href="#">24.- Análisis operacional de daños de inundación costera y fluvial mediante Redes Sociales </a></span>
        <div class="acc-container">
        <div class="content"> El Sistema Operacional de Daños de Inundación, denominado SODIN http://sodin.ihcantabria.es , monitoriza las 
condiciones ambientales de ríos y costas en tiempo real, permitiendo desencadenar la búsqueda de mensajes relacionados con eventos de inundación 
fluvial y costeros en Redes Sociales. En la actualidad, el Sistema hace uso del Computer Vision API y del Text Analytics API de Microsoft (más 
información del Sistema puede consultarse en el siguiente <a hred="https://www.linkedin.com/pulse/sodin-luis-pedraz-polo/?published=t"> enlace </a>.Por lo tanto, el objetivo del proyecto será analizar alternativas y mejoras, diseñarlas, desarrollarlas e implementarlas en el flujo de datos del Sistema SODIN.  <br> <br> 

Responsable:Felipe Fernández
<br>Contacto: <b>felipe.fernandez@unican.es</b>
        </div>
        </div>


    	<!-- section 25 -->
        <span class="acc-trigger active"><a href="#">25.- Optimización de la simulación numérica del Sistema de Alerta de Tsunamis (IH-Tsusy) </a></span>
        <div class="acc-container">
        <div class="content"> IH-Tsunamis System (IH-TSUSY) es un Sistema de simulación y notificación de tsunamis en tiempo real basada en la 
detección y notificación de terremotos en cualquier punto del Globo.  http://tsunami.ihcantabria.com/
 El Sistema recibe la información sísmica que, en tiempo real, proporcionan agencias internacionales, como la estadounidense USGS. Con los datos 
captados IH-TSUSY evalúa si el sismo cumple las características necesarias para generar un tsunami, en cuyo caso simula numéricamente su propagación 
y proporciona a través de la app notificaciones y mapas interactivos que contienen diversos datos de interés, como la amplitud (o altura de ola) y 
los tiempos de viaje de la onda desde la zona donde ha sido generada hasta las áreas costeras potencialmente afectadas. En la actualidad la 
aplicación para Android “IH Tsunamis System” ha sido instalada por más de 9000 usuarios y actualmente está operativa en más de 2100 dispositivos en 
todo el mundo (16% USA, 15% Indonesia, 9% Germany, 5% Spain, 5% Brazil). El mayor hándicap del sistema de alerta reside en el tiempo necesario para la simulación del modelo numérico (entre una o dos horas). Por lo tanto, este proyecto analizaría las alternativas (por ejemplo uso de GPUs) y llevaría a cabo las acciones necesarias para diseñar, desarrollar e implementar la alternativa seleccionada en el Sistema IH-Tsusy.   <br><br>
Responsable:Felipe Fernández
<br>Contacto: <b>felipe.fernandez@unican.es</b>
        </div>
        </div>


    	<!-- section 26 -->
        <span class="acc-trigger active"><a href="#">26.- Aplicación de técnicas de Deep Learning en teledetección  </a></span>
        <div class="acc-container">
        <div class="content"> En este proyecto se pretende aplicar técnicas de aprendizaje profundo (Deep Learning) como clasificadores supervisados en el campo de la teledetección. En concreto, se propone la aplicación de este tipo de técnicas para clasificar hábitats de vegetación usando para ello imágenes del satélite Sentinel y otras fuentes de datos geo-referenciadas. El objetivo será evaluar diferentes arquitecturas de red haciendo uso de la herramienta TensorFlow, el lenguaje python y librerías específicas para el procesamiento de datos geo-referenciados.<br><br>
Responsable:Daniel San Martin
<br>Contacto: <b>daniel@predictia.es</b>
        </div>
        </div>


    	<!-- section 27 -->
        <span class="acc-trigger active"><a href="#">27.- <strike> Modelización topo-batimétrica a partir de monitorización con drones y PPK-GPS</strike>[ASIGNADO]   </a></span>
        <div class="acc-container">
        <div class="content"> 
En los últimos años, se ha producido un importante avance en la
estimación de modelos digitales del terreno con sistemas de bajo coste, basados en
fotogrametría de imágenes obtenidas con dron y rectificadas con sistemas de
posicionamiento de alta resolución GPS. El tratamiento de las imágenes para obtener la
batimetría (topografía submarina) requiere del uso de algoritmos específicos, ya que se
tiene que estimar de forma indirecta las profundidades a partir de la observación de la
superficie libre del océano. En este TFM se desarrollará la metodología para la
estimación de modelos topo-batimétricos en playas del litoral cántabro, que se están
monitorizando en estos últimos meses con drones y sistemas RTK-GPS y PPK-GPS.<br><br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>
        </div>
        </div>


    	<!-- section 28 -->
        <span class="acc-trigger active"><a href="#">28.- <strike>Predicción del Riesgo de inundación en Cantabria </strike> [ASIGNADO] </a></span>
        <div class="acc-container">
        <div class="content"> 
Los sucesos recientes de inundación de numerosas localidades de
Cantabria han puesto de manifiesto la necesidad de predecir el riesgo de inundación en
Cantabria. Para ello, se realizará un estudio combinando información histórica y
predicción de precipitaciones, bases de datos de usos del suelo, bases de datos
socioeconómicas, técnicas de clasificación y representación en entorno de sistemas de
información geográfica.
<br><br>Metodología a seguir:  https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0187011 <br><br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>
        </div>
        </div>


    	<!-- section 29 -->
        <span class="acc-trigger active"><a href="#">29.- Respuesta estructural de edificios históricos a partir de análisis dinámico-estadístico  </a></span>
        <div class="acc-container">
        <div class="content"> 
En este TFM se analizará la respuesta structural de edificios históricos
de Cantabria a partir del modelado de series temporales multivariadas, procedentes de la
monitorización de series temporales de sensores de deformación (desplazamiento e
inclinación) y series de variables meteorológicas (temperatura, velocidad del viento,
humedad). Se utilizarán modelos lineales y no lineales para predecir la deformación de
la estructura a partir de las variables meteorológicas.
<br><br>Material: Blanco et al (2018) An integrated structural health monitoring system for
determining local/global responses of historic masonry buildings, Struct Control Health
Monit. DOI: 10.1002/stc.2196<br><br>
Responsable:Fernando Mendez
<br>Contacto: <b>fernando.mendez@unican.es</b>
        </div>
        </div>



    	<!-- section 30 -->
        <span class="acc-trigger active"><a href="#">30.- Automated bug triaging system  </a></span>
        <div class="acc-container">
        <div class="content"> Bug classification and triaging is a tedious task in any large software project. 
These task is performed by hand and normally involves the identification of the best assignee, the 
identification of its impact or severity, etc. becoming a bottleneck when the number of bugs that need to be 
triaged is high. Moreover, bug triaging is an essential task as its correctness has a high impact in the whole 
project.
In this proposal the student will scout the state of the art regarding automated bug triaging systems, implementing an automated framework for bug triaging based on deep learning techniques. We will study several public bug trackers, as well as the (private and protected) issue tracker of the EGI.eu European e-Infrastructure.        

 <br><br> 
Responsable:Álvaro López <br>
Contacto: <b>aloga@ifca.unican.es</b>
</div>
        </div>


    	<!-- section 31 -->
        <span class="acc-trigger active"><a href="#">31.- Building a python tool for anonymizing sensitive data  </a></span>
        <div class="acc-container">
        <div class="content"> 

Anonymizing sensitive data is a critical task when dealing with
datasets that contain personal details (like health records, census,
cell towers records, etc.). There are several methods (privacy models)
for anomymizing data (like k-anonimity or l-diversity among many
others).

Although there are tools for anonymizing data (like ARX), Python lacks a
comprehensive anonymization library and tool. In this project we will
build a library for the Python language, implementing the most common
privacy models, so that these methods can be included in a machine
learning pipeline.
 <br><br> 
Responsable:Álvaro López <br>
Contacto: <b>aloga@ifca.unican.es</b>
</div>
        </div>


   

    <br/>

    <div class="accrodation">
        <p><b>Ofertas TFM 2017-2018</b></p>
        <br/>
    	<!-- section 1 -->
        <span class="acc-trigger active"><a href="#">1.- Evaluación y despliegue de tecnologías BigData mediante una arquitectura lambda sobre un IDS (ASIGNADO)</a></span>
        <div class="acc-container">
        <div class="content">
El objetivo de este Trabajo de Fin de Máster consiste en evaluar distintas tecnologías de BigData enfocadas a streaming y procesado de datos para, posteriormente, desplegar las soluciones elegidas sobre el IDS (Intrusion Detection System) del IFCA (Instituto de Física de Cantabria).
<br/><br/>
En líneas generales, se analizarán y evaluarán las posibles tecnologías existentes de streaming de datos (Apache Kafka) y de procesado, tanto por lotes (Apache Spark), como mediante streaming (Apache Flink). Las soluciones elegidas se desplegarán mediante una arquitectura lambda con el actual IDS desplegado en el IFCA, Snort.
<br/><br/>
Este trabajo implica conocer distintas tecnologías de streaming, procesado y transmisión de datos de BigData, así como la arquitectura de detección de intrusos instalada en el IFCA.
        </div>
        </div>
      
        <!-- section 2 -->
        <span class="acc-trigger"><a href="#">2.- Clasificacion de imagenes de especies de plancton utilizando Deep Learning (ASIGNADO)</a></span>
        <div class="acc-container">
        <div class="content">
Proyecto cuyo objetivo se centra en la clasificacion de imagenes de distintas especies de plancton. Para su realizacion se utilizaran algoritmos de aprendizaje atomatico y mas concretamente tecnicas avanzadas de Deep Learning. Tambien se hara uso de tecnologia relacionada con bases de datos no relacionales, como es MongoDB
        </div>
        </div>
               
        <!-- section 3 -->
        <span class="acc-trigger"><a href="#">3.- Análisis de perturbaciones en Fibra Óptica con técnicas de Machine Learning (ASIGNADO)</a></span>
        <div class="acc-container">
        <div class="content">
Se estudia la aplicación de técnicas de machine learning con el objeto de analizar e identificar perturbaciones que afecten a la transmisión de luz en fibra óptica. Para el estudio se usan datos recogidos de fibras ópticas con diferentes características y/o perturbaciones reales, proporcionados por el Grupo de Ingeniería Fotónica (GIF)
        </div>
        </div>
        
        <!-- section 4 -->
        <span class="acc-trigger"><a href="#">4.- Log clustering tool (ASIGNADO)</a></span>
        <div class="acc-container">
        <div class="content">
En la actualidad, la cantidad de información generada por los sitemas IT y de comunicaciones sigue en clara expansión, haciendo aún más difícil, si cabe, su gestión y monitorización. Existen en el mercado diversas herramientas para la correlación de alertas, que facilitan y ayudan a los operadores a supervisar los sistemas; no obstante, el problema de resumir y sintetizar la actividad de los sistemas, mediante la extracción de patrones, no ha sido tan ampliamente implementado a nuestro entender. 
<br/><br/>
Es por ello que este proyecto investigará diversos algoritmos, que permitan mediante su combinación, obtener un extracto fiable de la actividad diaria de un sistema IT (CPD). Los resultados deberán ser explotados mediante una interfact gráfica de usuario.
        </div>
        </div>





        
    </div>
    </div>




<!--     <div class="content_fullwidth"> -->
<!--         <p><h2><center>DE ACUERDO, ¿COMO ME MATRICULO?</center></h2></p> -->
<!--         <p>&nbsp;Al ser un máster muy especializado sólo hay un máximo de 25 plazas. Hay que hacer una preinscripción, que puedes realizar tanto en la Secretaria de la Facultad de Ciencias de la Universidad de Cantabria, rellenando un formulario impreso, como on-line a través de la plataforma de la UIMP:</p> -->
<!--         <br/> -->
<!--         <p align="center"><b><font color="red">El plazo de preinscripción está abierto hasta el 18 de Septiembre, pero no lo dejes para el último día!</font></b></p> -->
<!--         <br/><br/> -->
<!--         <p align="center"><a href="preinscripcion.html" class="readmore_but13"> Preinscribase desde aqui <i class="fa fa-arrow-circle-right"></i></a></p> -->
<!--     </div> -->


</div>


<div class="clearfix margin_top4"></div>


<div class="footer1">
<div class="container">
    <div class="one_fourth">
    <ul class="faddress">
        <p align="center"><img src="images/logo_3.png" alt="" /></p>
        <p align="center">Master en Data Science</p>
        
    </ul>
    </div><!-- end address -->

    <div class="one_fourth">
    <div class="ftags">
        <br/><br/>
        <p align="center"><a href="http://www.csic.es" target="blank"> <img src="images/csic.jpg" title ="csic" alt="csic" /></a><br/>Consejo Superior<br/>Investigaciones Científicas</p>
    </div>
    </div>

    <div class="one_fourth">
    <div class="twitter_feed">
        <br/><br/>
        <p align="center"><a href="http://www.uimp.es" target="blank"> <img src="images/uimp.jpg" title ="uimp" alt="uimp" /></a><br/>Universidad Internacional<br/>Menéndez Pelayo</p>
    </div>
    </div>

    <div class="one_fourth last">
        <br/><br/>
        <p align="center"><a href="http://www.unican.es" target="blank"> <img src="images/uc.jpg" title ="uc" alt="uc" /></a><br/>Universidad de Cantabria</p>
    </div>
</div>
</div>



<div class="clearfix"></div>



<div class="copyright_info">
<div class="container">
    <div class="one_half">
<!--         <i class="fa fa-pencil"></i> <a class="nav-link " href="preinscripcion.html">Preinscripcion</a> -->
<!--         &nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;&nbsp; -->
        <i class="fa fa-comment"></i> <a class="nav-link " href="faq.html">Preguntas Frecuentes</a>
        &nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;&nbsp;
        <i class="fa fa-envelope"></i> <a class="nav-link " href="contacto.html">Contacto</a>
    </div>
    
    <div class="one_half last">
        <ul class="footer_social_links">
            Copyright © 2020 | Todos los derechos reservados.
        </ul>
    </div>
</div>
</div>



<a href="#" class="scrollup">Scroll</a>



</div>


    
<!-- ######### JS FILES ######### -->
<!-- get jQuery from the google apis -->
<script type="text/javascript" src="js/universal/jquery.js"></script>

<!-- style switcher -->
<script src="js/style-switcher/jquery-1.js"></script>
<script src="js/style-switcher/styleselector.js"></script>

<!-- SLIDER REVOLUTION 4.x SCRIPTS  -->
<script type="text/javascript" src="js/revolutionslider/rs-plugin/js/jquery.themepunch.plugins.min.js"></script>
<script type="text/javascript" src="js/revolutionslider/rs-plugin/js/jquery.themepunch.revolution.min.js"></script>

<!-- mega menu -->
<script src="js/mainmenu/bootstrap.min.js"></script>
<script src="js/mainmenu/fhmm.js"></script>

<!-- jquery jcarousel -->
<script type="text/javascript" src="js/carousel/jquery.jcarousel.min.js"></script>

<!-- scroll up -->
<script src="js/scrolltotop/totop.js" type="text/javascript"></script>

<!-- tabs -->
<script src="js/tabs/assets/js/responsive-tabs.min.js" type="text/javascript"></script>

<!-- jquery jcarousel -->
<script type="text/javascript">
    jQuery(document).ready(function() {
            jQuery('#mycarouselthree').jcarousel();
    });
</script>

<!-- accordion -->
<script type="text/javascript" src="js/accordion/custom.js"></script>

<!-- REVOLUTION SLIDER -->
<script type="text/javascript" src="js/revolutionslider/rs-plugin/js/custom.js"></script>

<!-- sticky menu -->
<script type="text/javascript" src="js/mainmenu/sticky.js"></script>
<script type="text/javascript" src="js/mainmenu/modernizr.custom.75180.js"></script>

<!-- progress bar -->
<script src="js/progressbar/progress.js" type="text/javascript" charset="utf-8"></script>

<!-- cubeportfolio -->
<script type="text/javascript" src="js/cubeportfolio/jquery.cubeportfolio.min.js"></script>
<script type="text/javascript" src="js/cubeportfolio/main4.js"></script>

<!-- carousel -->
<script defer src="js/carousel/jquery.flexslider.js"></script>
<script defer src="js/carousel/custom.js"></script>

<!-- lightbox -->
<script type="text/javascript" src="js/lightbox/jquery.fancybox.js"></script>
<script type="text/javascript" src="js/lightbox/custom.js"></script>


<script type="text/javascript">
    // Menu drop down effect
    $('.dropdown-toggle').dropdownHover().dropdown();
    $(document).on('click', '.fhmm .dropdown-menu', function(e) {
      e.stopPropagation()
    })
</script>

</body>
</html>
